<!DOCTYPE html>
<html lang="en">

<head>
	<meta name="generator" content="Hugo 0.115.2">
    <link rel="stylesheet" href="/styles/work.css"> 


    <title>Karina Nguyen | Karina Nguyen</title>
    <link rel="canonical" href="http://karinanguyen.com/" />

    
    <meta property="og:url" content="http://karinanguyen.com/" />
    <meta property="og:title" content="Karina Nguyen" />
    <meta property="og:description" content="" />
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Karina Nguyen">
    <meta name="twitter:description" content="">

    
</head>

<body>
    <nav class="tabs">
    <a href="/" >Home</a>
    <a href="/projects/" >Work & Projects</a>
    
    <a href="/writing/" >Writing </a> 
    
</nav>

    <main
        >

        

<div class="main-paragraph">
  <p class="front-header">Karina Nguyen</p>

  <p class="front-text">
    I prototype human-AI interfaces to explore novel and interpretable form
    factors for language model capabilities and conduct AI safety research at
    <mark>Anthropic</mark>. Through data visualizations I also try to bring
    research insights to life, telling the story of the most transformative
    technology of our time. Previously, as a design engineer I collaborated on R&D prototypes,
    journalism tools, and product features with
    teams at Primer.ai, Dropbox, Square, and the New York Times.
  </p>
  

  
  

  <p class="front-subheader">Research</p>
  <p class="front-text">
    I'm interested in AI alignment and interpretability research. In my last
    year of undergrad ('22) I worked on robustness and continual learning evaluations
    in computer vision, supervised by Joseph Gonzalez and Lisa Dunlap at
    <mark>Berkeley AI Research</mark>.
    
  </p>

  <div class="publications">
    <div class="paper">
      <p class="title">
        Question Decomposition Improves the Faithfulness of Model-Generated Reasoning
      </p>
      <p class="authors">
        Ansh Radhakrishnan, <a>Karina Nguyen</a>, +18
        more, Jared Kaplan, Jan Brauner, Samuel R. Bowman, Ethan Perez
      </p>
      <p class="details">
        Decomposing questions into subtasks in separate contexts improves reasoning faithfulness over chain of thought (CoT). This maintains some CoT performance gains while enabling safer, more verifiable model behavior. 
      </p>

      <div class="misc">
        <div>[<a href="https://arxiv.org/pdf/2307.11768.pdf">Paper</a>]</div>
        <div>
          [<a
            href="https://github.com/anthropics/DecompositionFaithfulnessPaper"
            >Prompts</a
          >]
        </div>
      </div>
    </div>
    <div class="paper">
      <p class="title">
        Towards Measuring the Representation of Subjective Global Opinions in
        Language Models
      </p>
      <p class="authors">
        Esin Durmus, <a>Karina Nguyen</a>, Thomas I Liao, Nicholas Schiefer, +11
        more, Jared Kaplan, Jack Clark, Deep Ganguli
      </p>
      <p class="details">
        We develop a method to test global opinions represented in language
        models.
      </p>
      <p class="type">In submission 2023</p>

      <div class="misc">
        <div>[<a href="https://arxiv.org/pdf/2306.16388.pdf">Paper</a>]</div>
        <div>
          [<a
            href="https://huggingface.co/datasets/Anthropic/llm_global_opinions"
            >Dataset</a
          >]
        </div>
        <div>
          [<a href="https://llmglobalvalues.anthropic.com/">Interactive Map</a>]
        </div>
      </div>
    </div>
    <div class="paper">
      <p class="title">
        Discovering Language Model Behaviors with Model-Written Evaluations
      </p>
      <p class="authors">
        Ethan Perez, Sam Ringer*, Kamile Luko≈°iute*, <a>Karina Nguyen*</a>,
        Edwin Chen, Scott Heiner, +55 more, Nicholas Schiefer, Jared Kaplan
      </p>
      <p class="details">
        We test LMs using >150 LM-written evaluations, finding cases of inverse
        scaling, where models exhibit sycophantic behaviors.
      </p>
      <p class="type">ACL'23 (Findings)</p>

      <div class="misc">
        <div>[<a href="https://arxiv.org/abs/2212.09251">Paper</a>]</div>
        <div>[<a href="https://github.com/anthropics/evals">Evals</a>]</div>
        <div>
          [<a href="https://www.evals.anthropic.com/model-written/"
            >Data Visualization</a
          >]
        </div>
        <div>
          [<a
            href="https://huggingface.co/datasets/Anthropic/model-written-evals"
            >Dataset</a
          >]
        </div>
      </div>
    </div>
    <div class="paper">
      <p class="title">
        FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling
      </p>
      <p class="authors">
        Wei-Yin Ko, Daniel D'souza, <a>Karina Nguyen</a>, Randall Balestriero,
        Sara Hooker
      </p>
      <p class="details">
        We find compelling and powerful gains in worst-k and minority group
        performance, i.e. fairness naturally emerges from ensembling.
      </p>
      <p class="type">In submission 2023</p>

      <div class="misc">
        <div>[<a href="https://arxiv.org/pdf/2303.00586.pdf">Paper</a>]</div>
        <div>
          [<a href="https://github.com/dsouzadaniel/fair_ensemble">Code</a>]
        </div>
        <div>[<a href="https://fair-ensemble.github.io/">Website</a>]</div>
        <div>
          [<a
            href="https://colab.research.google.com/drive/1kNdgQlJdCAiOaLxYMpLhp0NoAdPZGTpJ?usp=sharing"
            >Interactive Notebook</a
          >]
        </div>
      </div>
    </div>
    <div class="paper">
        <p class="title">
            Towards Semantically-Aware UI Design Tools: Design, Implementation and Evaluation of Semantic Grouping Guidelines
        </p>
        <p class="authors">
          Peitong Duan, Bjorn Hartmann, <a>Karina Nguyen</a>, Yang Li, Marti Hearst, Meredith Ringel Morris
        </p>
        <p class="details">
          We develop computational metric to measure semantic grouping UI violations.
        </p>
        <p class="type">To appear at ICML Workshop'23</p>
  
        
      </div>
  </div>

  

  <p class="front-subheader">Investigations</p>

  <p class="front-text">
    My work in visual investigative journalism & human rights involved extensive
    data collection, evidence verification, satellite analysis, 3D
    reconstructions, legal submissions, investigative tools, and applied remote
    sensing:
  </p>

  <ul class="front-company-list">
    <li>
      <a
        href="https://www.bloomberg.com/graphics/2022-ukraine-culture-russia-war-map-building-preservation/"
      >
        Bloomberg CityLab
      </a>
    </li>
    <li>
      <a
        href="https://www.wired.com/story/cyber-war-crimes-sandworm-russia-ukraine/"
        >Wired</a
      >
    </li>
    <li>
      <a href="https://www.youtube.com/watch?v=ysAAZisYiUg">New York Times</a>
    </li>
    <li>
      <a
        href="https://www.washingtonpost.com/investigations/2020/07/14/george-floyd-protests-police-blinding/?arc404=true"
        >Washington Post</a
      >
    </li>
    <li>
      <a
        href="https://www.cnn.com/2022/06/10/tech/ukraine-war-crimes-blockchain/index.html"
        >CNN</a
      >
    </li>
    <li>
      <a
        href="https://apnews.com/article/myanmar-business-b2187c696e428139437778aeab0c43d4"
        >Associated Press</a
      >
    </li>
    <li>
      <a
        href="https://www.bellingcat.com/news/2022/03/17/hospitals-bombed-and-apartments-destroyed-mapping-incidents-of-civilian-harm-in-ukraine/"
        >Bellingcat</a
      >
    </li>
    <li>
      <a href="https://situ.nyc/research/projects/after-the-strike"
        >SITU Research</a
      >
    </li>
    <li>
      <a
        href="https://www.atlanticcouncil.org/blogs/new-atlanticist/two-weeks-that-shook-kharkiv/"
        >The Atlantic Council</a
      >
    </li>
    <li>
      <a href="https://teargas.amnesty.org/#top">Amnesty International</a>
    </li>
  </ul>

  

  <p class="front-subheader">Say Hi!</p>

  <p class="front-text">
    <ul class="front-company-list">
        <li>
          <a
            href="https://twitter.com/karinanguyen_"
          >
            Twitter
          </a>
        </li>
        <li>
            <a
              href="https://semaphore.substack.com/"
            >
            Newsletter
            </a>
          </li>
        <li>
            <a
              href="mailto:karina@anthropic.com"
            >
              Email
            </a>
          </li>
          <li>
            <a
              href="https://scholar.google.com/citations?user=cn62i2kAAAAJ&hl=en&oi=ao"
            >
            Google Scholar
            </a>
          </li>
    </ul>
    
  </p>
</div>


    </main>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Serif:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="/css/main.css" />
<link rel="alternate" type="application/rss+xml" href="/index.xml" title="">
</body>

</html>